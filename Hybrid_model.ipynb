{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24febc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                      \n",
    "import os, random, math, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "np.random.seed(SEED)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "                                                                      \n",
    "                       \n",
    "         \n",
    "                                                \n",
    "                                \n",
    "                                \n",
    "                                     \n",
    "                                   \n",
    "                                  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cafaef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user.csv columns: ['Unnamed: 0', 'user_id', 'age_group', 'health_goal', 'baseline_activity_level', 'engagement_persona']\n",
      "PT_data.cleaned.csv columns: ['trainer_id', 'name', 'videos_count', 'total_likes', 'workout_recommendations', 'athlete_rating', 'years_experience', 'specialities']\n",
      "engagement_data.csv columns: ['interaction_id', 'timestamp', 'user_id', 'trainer_id', 'video_completion_rate', 'adherence_score', 'feedback_score']\n"
     ]
    }
   ],
   "source": [
    "                                                             \n",
    "DATA_DIR = \"./\"                                     \n",
    "USERS_CSV = os.path.join(DATA_DIR, \"user.csv\")\n",
    "PT_CSV    = os.path.join(DATA_DIR, \"PT_data.cleaned.csv\")\n",
    "ENG_CSV   = os.path.join(DATA_DIR, \"engagement_data.csv\")\n",
    "\n",
    "users = pd.read_csv(USERS_CSV)\n",
    "pt    = pd.read_csv(PT_CSV)\n",
    "eng   = pd.read_csv(ENG_CSV)\n",
    "\n",
    "print(\"user.csv columns:\", list(users.columns))\n",
    "print(\"PT_data.cleaned.csv columns:\", list(pt.columns))\n",
    "print(\"engagement_data.csv columns:\", list(eng.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "400c2e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using physio name column: name\n",
      "Provider metric columns for WSM: ['total_likes', 'workout_recommendations', 'athlete_rating', 'years_experience']\n"
     ]
    }
   ],
   "source": [
    "                                                                        \n",
    "\n",
    "                                                             \n",
    "REQUIRED_USER = [\"user_id\", \"health_goal\"]\n",
    "for c in REQUIRED_USER:\n",
    "    if c not in users.columns:\n",
    "        raise ValueError(f\"Missing '{c}' in user.csv\")\n",
    "\n",
    "                                                  \n",
    "if \"trainer_id\" not in pt.columns:\n",
    "    raise ValueError(\"Missing 'trainer_id' in PT_data.cleaned.csv\")\n",
    "if \"specialities\" not in pt.columns:\n",
    "    raise ValueError(\"Missing 'specialities' in PT_data.cleaned.csv\")\n",
    "if \"athlete_rating\" not in pt.columns:\n",
    "    raise ValueError(\"Missing 'athlete_rating' in PT_data.cleaned.csv\")\n",
    "if \"name\" not in pt.columns:\n",
    "    raise ValueError(\"Missing 'name' (physio name) in PT_data.cleaned.csv\")\n",
    "\n",
    "                                                       \n",
    "if \"user_id\" not in eng.columns or \"trainer_id\" not in eng.columns:\n",
    "    raise ValueError(\"engagement_data.csv must have 'user_id' and 'trainer_id'\")\n",
    "if \"timestamp\" not in eng.columns:\n",
    "                                                          \n",
    "    print(\"Note: 'timestamp' not found in engagement_data.csv; will use random/leave-one-out split fallback.\")\n",
    "\n",
    "                                                                   \n",
    "                                     \n",
    "pt = pt.rename(columns={\"trainer_id\": \"physio_id\"})\n",
    "eng = eng.rename(columns={\"trainer_id\": \"physio_id\"})\n",
    "\n",
    "                                         \n",
    "physio_name_col = \"name\"\n",
    "\n",
    "                                                                   \n",
    "PT_PROVIDER_FEATURES = [c for c in [\"total_likes\",\n",
    "                                    \"workout_recommendations\",\n",
    "                                    \"athlete_rating\",\n",
    "                                    \"years_experience\"] if c in pt.columns]\n",
    "\n",
    "print(\"Using physio name column:\", physio_name_col)\n",
    "print(\"Provider metric columns for WSM:\", PT_PROVIDER_FEATURES)\n",
    "\n",
    "                            \n",
    "users[\"user_id\"]  = users[\"user_id\"].astype(int)\n",
    "pt[\"physio_id\"]   = pt[\"physio_id\"].astype(int)\n",
    "eng[\"user_id\"]    = eng[\"user_id\"].astype(int)\n",
    "eng[\"physio_id\"]  = eng[\"physio_id\"].astype(int)\n",
    "\n",
    "                                                        \n",
    "ts_col = \"timestamp\" if \"timestamp\" in eng.columns else None\n",
    "if ts_col:\n",
    "    eng[ts_col] = pd.to_datetime(eng[ts_col], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8466595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                              \n",
    "                           \n",
    "                                \n",
    "                                    \n",
    "\n",
    "def _norm_text(x):\n",
    "    if pd.isna(x): \n",
    "        return \"\"\n",
    "    return str(x).lower().strip()\n",
    "\n",
    "users[\"_goal_text\"] = users[\"health_goal\"].apply(_norm_text)\n",
    "pt[\"_spec_text\"]    = pt[\"specialities\"].apply(_norm_text)\n",
    "\n",
    "                                                              \n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "X_spec = tfidf.fit_transform(pt[\"_spec_text\"])                  \n",
    "X_goal = tfidf.transform(users[\"_goal_text\"])                   \n",
    "\n",
    "                                                           \n",
    "cosine = X_goal @ X_spec.T                                                                                            \n",
    "                \n",
    "cosine = cosine.tocsr().astype(np.float32)\n",
    "cosine.data = np.clip(cosine.data, 0.0, 1.0)\n",
    "\n",
    "                                                        \n",
    "def token_set(s): \n",
    "    return set([t for t in _norm_text(s).split() if t])\n",
    "\n",
    "user_sets = users[\"_goal_text\"].apply(token_set).tolist()\n",
    "pt_sets   = pt[\"_spec_text\"].apply(token_set).tolist()\n",
    "\n",
    "                                           \n",
    "rows, cols, vals = [], [], []\n",
    "for i, uset in enumerate(user_sets):\n",
    "    if not uset: \n",
    "        continue\n",
    "                                                                                   \n",
    "    row = cosine.getrow(i)\n",
    "    cand_idx = row.indices if row.nnz > 0 else np.arange(len(pt))\n",
    "                                          \n",
    "    for j in cand_idx:\n",
    "        pset = pt_sets[j]\n",
    "        if not pset: \n",
    "            jacc = 0.0\n",
    "        else:\n",
    "            inter = len(uset & pset)\n",
    "            union = len(uset | pset)\n",
    "            jacc = inter/union if union>0 else 0.0\n",
    "        if jacc>0:\n",
    "            rows.append(i); cols.append(j); vals.append(jacc)\n",
    "\n",
    "J = sparse.csr_matrix((vals, (rows, cols)), shape=(len(users), len(pt)), dtype=np.float32)\n",
    "\n",
    "                                                     \n",
    "match_score = 0.7 * cosine + 0.3 * J\n",
    "match_score.data = np.clip(match_score.data, 0.0, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325d330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                          \n",
    "                                                                \n",
    "                                                                       \n",
    "WSM_WEIGHTS = {\n",
    "    \"athlete_rating\":         0.60,\n",
    "    \"total_likes\":            0.15,\n",
    "    \"workout_recommendations\":0.15,\n",
    "    \"years_experience\":       0.10\n",
    "}\n",
    "                                                   \n",
    "WSM_WEIGHTS = {k:v for k,v in WSM_WEIGHTS.items() if k in PT_PROVIDER_FEATURES}\n",
    "weight_sum = sum(WSM_WEIGHTS.values())\n",
    "if weight_sum == 0:\n",
    "    raise ValueError(\"No provider metric columns found for WSM reuse. Ensure at least one of: total_likes, workout_recommendations, athlete_rating, years_experience\")\n",
    "\n",
    "for k in list(WSM_WEIGHTS):\n",
    "    WSM_WEIGHTS[k] /= weight_sum\n",
    "\n",
    "pt_w = pt.copy()\n",
    "                                            \n",
    "def winsorize_minmax(s, p=5):\n",
    "    s = s.astype(float)\n",
    "    lo, hi = np.nanpercentile(s, [p, 100-p])\n",
    "    s = s.clip(lo, hi)\n",
    "                             \n",
    "    if float(hi - lo) == 0:\n",
    "        return pd.Series(np.zeros_like(s, dtype=float), index=s.index)\n",
    "    return (s - lo) / (hi - lo)\n",
    "\n",
    "for col in WSM_WEIGHTS:\n",
    "    pt_w[f\"ws_{col}\"] = winsorize_minmax(pt_w[col])\n",
    "\n",
    "pt_w[\"wsm_raw\"] = 0.0\n",
    "for col, w in WSM_WEIGHTS.items():\n",
    "    pt_w[\"wsm_raw\"] += w * pt_w[f\"ws_{col}\"]\n",
    "\n",
    "                                         \n",
    "pt_w[\"wsm_score\"] = minmax_scale(pt_w[\"wsm_raw\"].fillna(pt_w[\"wsm_raw\"].median()))\n",
    "pt = pt.merge(pt_w[[\"physio_id\",\"wsm_score\"]], on=\"physio_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebeab618",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                           \n",
    "ALPHA = 0.40  \n",
    "\n",
    "                                                                                                          \n",
    "U, P = match_score.shape\n",
    "usr_idx, phy_idx = match_score.nonzero()\n",
    "content_pairs = pd.DataFrame({\"u_idx\": usr_idx, \"p_idx\": phy_idx})\n",
    "content_pairs[\"match_score\"] = match_score[usr_idx, phy_idx].A1\n",
    "\n",
    "                       \n",
    "content_pairs[\"user_id\"]  = users.loc[content_pairs[\"u_idx\"], \"user_id\"].to_numpy()\n",
    "content_pairs[\"physio_id\"]= pt.loc[content_pairs[\"p_idx\"], \"physio_id\"].to_numpy()\n",
    "\n",
    "                          \n",
    "content_pairs = content_pairs.merge(pt[[\"physio_id\",\"wsm_score\"]], on=\"physio_id\", how=\"left\")\n",
    "content_pairs[\"wsm_score\"] = content_pairs[\"wsm_score\"].fillna(content_pairs[\"wsm_score\"].median())\n",
    "\n",
    "content_pairs[\"content_score\"] = ALPHA*content_pairs[\"match_score\"] + (1-ALPHA)*content_pairs[\"wsm_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce01d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                                                                                       \n",
    "def split_last7_min2_fallback(eng_df, ts_col_name: str | None = \"timestamp\"):\n",
    "    \"\"\"\n",
    "    Returns (train_eng, test_eng):\n",
    "      • Test = each user's events in the last 7 days IF that yields ≥2 test events\n",
    "      • Else Test = that user's single last interaction\n",
    "      • Train = everything else\n",
    "    Expects at least 'user_id' and a timestamp column (default 'timestamp').\n",
    "    Optional: 'interaction_id' for deterministic ordering in ties.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if eng_df is None or len(eng_df) == 0:\n",
    "        return eng_df.copy(), eng_df.copy()\n",
    "\n",
    "                                                                            \n",
    "    if not ts_col_name or ts_col_name not in eng_df.columns:\n",
    "        tmp = eng_df.copy()\n",
    "        order_cols = [\"user_id\"]\n",
    "        if \"interaction_id\" in tmp.columns:\n",
    "            order_cols.append(\"interaction_id\")\n",
    "        tmp = tmp.sort_values(order_cols)\n",
    "        test = tmp.groupby(\"user_id\", as_index=False).tail(1)\n",
    "        train = tmp.drop(test.index)\n",
    "        return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "\n",
    "                              \n",
    "    ev = eng_df.copy()\n",
    "    ev[ts_col_name] = pd.to_datetime(ev[ts_col_name], errors=\"coerce\")\n",
    "    order_cols = [\"user_id\", ts_col_name]\n",
    "    if \"interaction_id\" in ev.columns:\n",
    "        order_cols.append(\"interaction_id\")\n",
    "    ev = ev.sort_values(order_cols)\n",
    "\n",
    "                                 \n",
    "    last_ts = ev.groupby(\"user_id\")[ts_col_name].max()\n",
    "    cutoff  = (last_ts - pd.Timedelta(days=7)).rename(\"cutoff\")\n",
    "    ev = ev.merge(cutoff.reset_index(), on=\"user_id\", how=\"left\")\n",
    "    ev[\"_in_last7\"] = ev[ts_col_name] >= ev[\"cutoff\"]\n",
    "\n",
    "    win_counts = ev.groupby(\"user_id\")[\"_in_last7\"].sum()\n",
    "    ok_users = win_counts[win_counts >= 2].index\n",
    "    fb_users = win_counts[win_counts <  2].index\n",
    "\n",
    "                                           \n",
    "    last_idx_fb = (\n",
    "        ev.loc[ev[\"user_id\"].isin(fb_users)]\n",
    "          .groupby(\"user_id\", as_index=False)\n",
    "          .tail(1)\n",
    "          .index\n",
    "    )\n",
    "\n",
    "    test_mask  = (ev[\"_in_last7\"] & ev[\"user_id\"].isin(ok_users)) | (ev.index.isin(last_idx_fb))\n",
    "    train_mask = ~test_mask\n",
    "\n",
    "    train = ev.loc[train_mask].drop(columns=[\"cutoff\",\"_in_last7\"]).copy()\n",
    "    test  = ev.loc[test_mask ].drop(columns=[\"cutoff\",\"_in_last7\"]).copy()\n",
    "    return train.reset_index(drop=True), test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee678cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "                                                                                                      \n",
    "signal_weights = {\n",
    "    \"video_completion_rate\": 1.0,\n",
    "    \"adherence_score\":       5.0,\n",
    "    \"feedback_score\":        4.0,\n",
    "}\n",
    "sig_cols_present = [c for c in eng.columns if c in signal_weights]\n",
    "\n",
    "if len(sig_cols_present) == 0:\n",
    "    eng[\"_strength\"] = 1.0\n",
    "else:\n",
    "    e = np.zeros(len(eng), dtype=float)\n",
    "    for c in sig_cols_present:\n",
    "        s = pd.to_numeric(eng[c], errors=\"coerce\")\n",
    "        if s.notna().any() and s.max() != s.min():\n",
    "            s = (s - s.min()) / (s.max() - s.min())\n",
    "        else:\n",
    "            s = pd.Series(0.0, index=eng.index)\n",
    "        e += signal_weights[c] * s.fillna(0.0).to_numpy()\n",
    "    eng[\"_strength\"] = e\n",
    "\n",
    "                                                      \n",
    "HALF_LIFE_DAYS = 30.0\n",
    "ts_col = \"timestamp\" if \"timestamp\" in eng.columns else None\n",
    "if ts_col:\n",
    "    eng[ts_col] = pd.to_datetime(eng[ts_col], errors=\"coerce\")\n",
    "    max_ts = eng[ts_col].max()\n",
    "    age_days = (max_ts - eng[ts_col]).dt.total_seconds().div(86400.0)\n",
    "    decay = np.exp(-np.log(2.0) * age_days / HALF_LIFE_DAYS)\n",
    "    eng[\"_strength\"] = eng[\"_strength\"] * decay.fillna(1.0)\n",
    "\n",
    "                                                            \n",
    "def build_split_from_eng(eng_df, ts_col_name):\n",
    "    if \"is_test\" in eng_df.columns:\n",
    "        train_idx = eng_df[~eng_df[\"is_test\"]].index\n",
    "        test_idx  = eng_df[ eng_df[\"is_test\"]].index\n",
    "        return eng_df.loc[train_idx].copy(), eng_df.loc[test_idx].copy()\n",
    "    if ts_col_name:\n",
    "        tmp = eng_df.sort_values([\"user_id\", ts_col_name])\n",
    "        test = tmp.groupby(\"user_id\", as_index=False).tail(1)\n",
    "        train = tmp.drop(test.index)\n",
    "        return train.copy(), test.copy()\n",
    "                                              \n",
    "    rng = np.random.default_rng(42)\n",
    "    test_idx = eng_df.groupby(\"user_id\").apply(lambda g: g.sample(1, random_state=42).index[0]).values\n",
    "    test = eng_df.loc[test_idx].copy()\n",
    "    train = eng_df.drop(test_idx).copy()\n",
    "    return train, test\n",
    "train_eng, test_eng = split_last7_min2_fallback(eng, (ts_col or \"timestamp\"))\n",
    "                                                                          \n",
    "train_ui = train_eng.groupby([\"user_id\",\"physio_id\"], as_index=False)[\"_strength\"].sum()\n",
    "                                                       \n",
    "all_user_ids  = users[\"user_id\"].astype(int).tolist()\n",
    "all_item_ids  = pt[\"physio_id\"].astype(int).tolist()\n",
    "u2i = {u:i for i,u in enumerate(all_user_ids)}\n",
    "p2j = {p:j for j,p in enumerate(all_item_ids)}\n",
    "\n",
    "                                                               \n",
    "rows = train_ui[\"user_id\"].map(u2i).to_numpy()\n",
    "cols = train_ui[\"physio_id\"].map(p2j).to_numpy()\n",
    "vals = train_ui[\"_strength\"].astype(float).to_numpy()\n",
    "U, P = len(all_user_ids), len(all_item_ids)\n",
    "R = sparse.csr_matrix((vals, (rows, cols)), shape=(U, P), dtype=float)\n",
    "\n",
    "                                                                                       \n",
    "                                             \n",
    "nmf = NMF(\n",
    "    n_components=64, \n",
    "    init=\"nndsvd\", \n",
    "    random_state=42, \n",
    "    max_iter=300, \n",
    "    alpha_W=0.01, alpha_H=0.01, l1_ratio=0.0\n",
    ")\n",
    "W = nmf.fit_transform(R)                    \n",
    "H = nmf.components_                         \n",
    "\n",
    "                                                                             \n",
    "cf_raw = W @ H                              \n",
    "                  \n",
    "cf_min = cf_raw.min(axis=1, keepdims=True)\n",
    "cf_max = cf_raw.max(axis=1, keepdims=True)\n",
    "denom  = np.where((cf_max - cf_min) == 0, 1.0, (cf_max - cf_min))\n",
    "cf_scaled = (cf_raw - cf_min) / denom\n",
    "\n",
    "                                                                                             \n",
    "cf_df = pd.DataFrame(cf_scaled, columns=all_item_ids, index=all_user_ids)\n",
    "cf_df.index.name = \"user_id\"\n",
    "cf_df = cf_df.reset_index()\n",
    "cf_long = cf_df.melt(id_vars=[\"user_id\"], var_name=\"physio_id\", value_name=\"cf_score\")\n",
    "cf_long[\"physio_id\"] = cf_long[\"physio_id\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65aaf07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id                 health_goal  physio name  \\\n",
      "0        1      Flexibility & Mobility  Trainer 593   \n",
      "1        1      Flexibility & Mobility  Trainer 838   \n",
      "2        1      Flexibility & Mobility  Trainer 657   \n",
      "3        1      Flexibility & Mobility  Trainer 339   \n",
      "4        1      Flexibility & Mobility   Trainer 92   \n",
      "5        2  General Fitness & Wellness    Trainer 7   \n",
      "6        2  General Fitness & Wellness  Trainer 416   \n",
      "7        2  General Fitness & Wellness  Trainer 174   \n",
      "8        2  General Fitness & Wellness    Trainer 1   \n",
      "9        2  General Fitness & Wellness  Trainer 635   \n",
      "\n",
      "                                        specialities  athlete_rating  \\\n",
      "0                                        Flexibility             4.7   \n",
      "1                                        Flexibility             4.7   \n",
      "2                                        Flexibility             4.8   \n",
      "3                                        Flexibility             4.0   \n",
      "4                                        Flexibility             4.0   \n",
      "5  Prenatal Fitness, Functional Training, Sports-...             4.9   \n",
      "6                     Yoga, Cardio, Prenatal Fitness             3.6   \n",
      "7                                    Elderly Fitness             4.9   \n",
      "8                             Prenatal Fitness, Yoga             4.2   \n",
      "9             Powerlifting, Elderly Fitness, Pilates             4.8   \n",
      "\n",
      "   years_experience  total_likes  videos_count  workout_recommendations  \\\n",
      "0                19       199143           317                      191   \n",
      "1                22        78568           453                      192   \n",
      "2                11        11264            28                       67   \n",
      "3                22       247027           457                       64   \n",
      "4                15       295069           420                       97   \n",
      "5                15       401813           407                      143   \n",
      "6                 7        61338           497                       22   \n",
      "7                24        94634           176                      154   \n",
      "8                22       289134           247                      154   \n",
      "9                17       188365           369                       89   \n",
      "\n",
      "   score  rank  \n",
      "0  0.301     1  \n",
      "1  0.285     2  \n",
      "2  0.264     3  \n",
      "3  0.247     4  \n",
      "4  0.238     5  \n",
      "5  0.301     1  \n",
      "6  0.287     2  \n",
      "7  0.250     3  \n",
      "8  0.216     4  \n",
      "9  0.213     5  \n"
     ]
    }
   ],
   "source": [
    "                                                                                                   \n",
    "W_CONTENT = 0.35\n",
    "W_CF      = 0.65\n",
    "\n",
    "                            \n",
    "cand = content_pairs.merge(cf_long, on=[\"user_id\",\"physio_id\"], how=\"left\")\n",
    "cand[\"cf_score\"] = cand[\"cf_score\"].fillna(0.0)                      \n",
    "cand[\"score\"] = W_CONTENT*cand[\"content_score\"] + W_CF*cand[\"cf_score\"]\n",
    "\n",
    "                                    \n",
    "had_eng = set(map(tuple, train_eng[[\"user_id\",\"physio_id\"]]\n",
    "                  .drop_duplicates()\n",
    "                  .itertuples(index=False, name=None)))\n",
    "cand[\"is_cold_for_user\"] = ~cand[[\"user_id\",\"physio_id\"]].apply(tuple, axis=1).isin(had_eng)\n",
    "\n",
    "\n",
    "                                                                                   \n",
    "tie_noise = np.random.RandomState(SEED).rand(len(cand)) * 1e-9\n",
    "cand[\"tie_noise\"] = tie_noise\n",
    "\n",
    "                                                                         \n",
    "if \"years_experience\" in pt.columns:\n",
    "    cand = cand.merge(\n",
    "        pt[[\"physio_id\",\"years_experience\"]].rename(columns={\"years_experience\":\"years_experience_tb\"}),\n",
    "        on=\"physio_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "else:\n",
    "    cand[\"years_experience_tb\"] = 0.0\n",
    "\n",
    "def top5_with_one_cold(df_u):\n",
    "    df_u = df_u.sort_values(\n",
    "        by=[\"score\",\"wsm_score\",\"years_experience_tb\",\"tie_noise\"],\n",
    "        ascending=[False,False,False,False]\n",
    "    ).copy()\n",
    "\n",
    "    non_cold = df_u[~df_u[\"is_cold_for_user\"]]\n",
    "    cold     = df_u[df_u[\"is_cold_for_user\"]]\n",
    "\n",
    "    top_non_cold = non_cold.head(4)\n",
    "    if len(cold) > 0:\n",
    "        best_cold = cold.sort_values(\n",
    "            by=[\"content_score\",\"wsm_score\",\"years_experience_tb\",\"tie_noise\"],\n",
    "            ascending=[False,False,False,False]\n",
    "        ).head(1)\n",
    "    else:\n",
    "        best_cold = df_u.head(1)            \n",
    "        best_cold[\"is_cold_for_user\"] = True\n",
    "\n",
    "    outu = pd.concat([top_non_cold, best_cold], axis=0)\n",
    "\n",
    "    if len(outu) < 5:\n",
    "        need = 5 - len(outu)\n",
    "        remaining = df_u[~df_u.index.isin(outu.index)]\n",
    "        remaining = remaining[~remaining[\"is_cold_for_user\"]]                           \n",
    "        outu = pd.concat([outu, remaining.head(need)], axis=0)\n",
    "\n",
    "    if outu[\"is_cold_for_user\"].sum() > 1:\n",
    "        cold_rows = outu[outu[\"is_cold_for_user\"]].sort_values(\n",
    "            by=[\"content_score\",\"wsm_score\",\"years_experience_tb\",\"tie_noise\"],\n",
    "            ascending=[False,False,False,False]\n",
    "        )\n",
    "        keep = cold_rows.head(1).index\n",
    "        outu = pd.concat([outu[~outu.index.isin(cold_rows.index)], outu.loc[keep]], axis=0)\n",
    "\n",
    "    outu = outu.sort_values(\n",
    "        by=[\"score\",\"wsm_score\",\"years_experience_tb\",\"tie_noise\"],\n",
    "        ascending=[False,False,False,False]\n",
    "    ).head(5)\n",
    "    return outu\n",
    "\n",
    "top_rows = []\n",
    "for uid, g in cand.groupby(\"user_id\"):\n",
    "    top_rows.append(top5_with_one_cold(g))\n",
    "top = pd.concat(top_rows, axis=0).copy()\n",
    "\n",
    "                                                    \n",
    "                                                                                 \n",
    "extras_available = [c for c in [\"years_experience\",\"total_likes\",\"videos_count\",\"workout_recommendations\"] if c in pt.columns]\n",
    "\n",
    "                                                                     \n",
    "merge_cols = [\"physio_id\", physio_name_col, \"specialities\", \"athlete_rating\"] + extras_available\n",
    "out = top.merge(users[[\"user_id\",\"health_goal\"]], on=\"user_id\", how=\"left\")\\\n",
    "         .merge(pt[merge_cols], on=\"physio_id\", how=\"left\")\n",
    "\n",
    "                                \n",
    "ordered_cols = [\"user_id\",\"health_goal\", physio_name_col, \"specialities\",\"athlete_rating\"] + extras_available + [\"score\"]\n",
    "out = out[ordered_cols].copy()\n",
    "\n",
    "                              \n",
    "out[\"rank\"] = out.groupby(\"user_id\")[\"score\"].rank(method=\"first\", ascending=False).astype(int)\n",
    "out[\"score\"] = out[\"score\"].round(3)\n",
    "\n",
    "                                                          \n",
    "out = out.rename(columns={physio_name_col: \"physio name\"})\n",
    "\n",
    "                  \n",
    "out = out.sort_values(by=[\"user_id\",\"rank\"])\n",
    "print(out.head(10))\n",
    "\n",
    "                      \n",
    "out.to_csv(\"hybrid_top5_per_user.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4e3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                         \n",
    "                                                                                \n",
    "pop = train_ui.merge(pt[[\"physio_id\",\"wsm_score\"]], on=\"physio_id\", how=\"left\").groupby(\"physio_id\")[\"_strength\"].sum().reset_index()\n",
    "pop = pop.merge(pt[[\"physio_id\",\"wsm_score\"]], on=\"physio_id\", how=\"left\")\n",
    "pop = pop.sort_values(by=[\"_strength\",\"wsm_score\"], ascending=[False,False])\n",
    "\n",
    "def top5_baseline_for_user(uid):\n",
    "                                                                                    \n",
    "    i = users.index[users[\"user_id\"]==uid][0]\n",
    "    row = match_score.getrow(i)\n",
    "    cand_ids = pt.loc[row.indices, \"physio_id\"].tolist() if row.nnz>0 else pt[\"physio_id\"].tolist()\n",
    "    sub = pop[pop[\"physio_id\"].isin(cand_ids)]\n",
    "    return sub.head(5)[\"physio_id\"].tolist()\n",
    "\n",
    "                                                                                          \n",
    "def top5_wsm_for_user(uid):\n",
    "    g = content_pairs[content_pairs[\"user_id\"]==uid].copy()\n",
    "    g[\"content_wsm_only\"] = g[\"wsm_score\"]                                                                \n",
    "    g = g.sort_values(by=[\"content_wsm_only\"], ascending=False).head(5)\n",
    "    return g[\"physio_id\"].tolist()\n",
    "\n",
    "                                                   \n",
    "hybrid_top = out[[\"user_id\"]].copy()\n",
    "hybrid_top[\"physio_id_list\"] = out.groupby(\"user_id\")[\"physio name\"].transform(lambda s: 0)               \n",
    "                                                 \n",
    "hybrid_map = top.sort_values([\"user_id\",\"score\"], ascending=[True,False]).groupby(\"user_id\")[\"physio_id\"].apply(list).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "992a76dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected/evaluated metrics: ['Precision@10', 'Precision@5', 'Recall@10', 'Recall@5', 'nDCG@10', 'nDCG@5']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hybrid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision@10</th>\n",
       "      <td>0.007667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision@5</th>\n",
       "      <td>0.015335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.019247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.019247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nDCG@10</th>\n",
       "      <td>0.018062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nDCG@5</th>\n",
       "      <td>0.018902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Hybrid\n",
       "Metric                \n",
       "Precision@10  0.007667\n",
       "Precision@5   0.015335\n",
       "Recall@10     0.019247\n",
       "Recall@5      0.019247\n",
       "nDCG@10       0.018062\n",
       "nDCG@5        0.018902"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                                                                                                        \n",
    "                                                  \n",
    "\n",
    "import json, re, nbformat, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "                                                                               \n",
    "WSM_NOTEBOOK = \"C:/Users/DELL/OneDrive/Desktop/Code_files/WSM_Model.ipynb\"\n",
    "BASE_NOTEBOOK = \"C:/Users/DELL/OneDrive/Desktop/Code_files/Baseline_models_cleaned.ipynb\"\n",
    "\n",
    "METRIC_NAME_PATTERNS = [\n",
    "    r\"Precision@ ?(\\d+)\", r\"Recall@ ?(\\d+)\", r\"nDCG@ ?(\\d+)\", r\"MRR@ ?(\\d+)\", r\"MAP@ ?(\\d+)\",\n",
    "    r\"HitRate@ ?(\\d+)\", r\"HR@ ?(\\d+)\", r\"AUC\", r\"ROC[- ]?AUC\", r\"RMSE\", r\"MAE\"\n",
    "]\n",
    "\n",
    "def extract_metric_names(ipynb_path):\n",
    "    names = set()\n",
    "    try:\n",
    "        nb = nbformat.read(ipynb_path, as_version=4)\n",
    "        for cell in nb.cells:\n",
    "            if cell.cell_type not in (\"code\", \"markdown\"):\n",
    "                continue\n",
    "            txt = cell.source\n",
    "            for pat in METRIC_NAME_PATTERNS:\n",
    "                for m in re.findall(pat, txt, flags=re.IGNORECASE):\n",
    "                                                      \n",
    "                    if \"Precision\" in pat:\n",
    "                        names.add(f\"Precision@{m}\")\n",
    "                    elif \"Recall\" in pat:\n",
    "                        names.add(f\"Recall@{m}\")\n",
    "                    elif \"nDCG\" in pat:\n",
    "                        names.add(f\"nDCG@{m}\")\n",
    "                    elif \"MRR\" in pat and m:\n",
    "                        names.add(f\"MRR@{m}\")\n",
    "                    elif \"MAP\" in pat and m:\n",
    "                        names.add(f\"MAP@{m}\")\n",
    "                    elif \"HitRate\" in pat and m:\n",
    "                        names.add(f\"HitRate@{m}\")\n",
    "                    elif \"HR@\" in pat and m:\n",
    "                        names.add(f\"HitRate@{m}\")                       \n",
    "                    elif \"AUC\" in pat:\n",
    "                        names.add(\"AUC\")\n",
    "                    elif \"RMSE\" in pat:\n",
    "                        names.add(\"RMSE\")\n",
    "                    elif \"MAE\" in pat:\n",
    "                        names.add(\"MAE\")\n",
    "        return sorted(names)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] Could not read {ipynb_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "metric_names = set()\n",
    "for p in [WSM_NOTEBOOK, BASE_NOTEBOOK]:\n",
    "    metric_names.update(extract_metric_names(p))\n",
    "\n",
    "                                                        \n",
    "if not metric_names:\n",
    "    metric_names = {\"Precision@5\",\"Recall@5\",\"nDCG@5\",\"MRR@5\",\"MAP@5\",\"HitRate@5\"}\n",
    "\n",
    "metric_names = sorted(metric_names)\n",
    "print(\"Detected/evaluated metrics:\", metric_names)\n",
    "\n",
    "                                                                 \n",
    "                                                           \n",
    "test_truth = test_eng.groupby(\"user_id\")[\"physio_id\"].apply(set).to_dict()\n",
    "\n",
    "                                      \n",
    "def topk_hybrid(u, K):\n",
    "    return (hybrid_map.get(u, []) or [])[:K]\n",
    "\n",
    "USERS = users[\"user_id\"].tolist()\n",
    "\n",
    "                                                               \n",
    "def precision_at_k(recommended, relevant, k):\n",
    "    if not recommended: return 0.0\n",
    "    hits = sum(1 for r in recommended[:k] if r in relevant)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    if not relevant: return 0.0\n",
    "    hits = sum(1 for r in recommended[:k] if r in relevant)\n",
    "    return hits / len(relevant)\n",
    "\n",
    "def dcg_at_k(recommended, relevant, k):\n",
    "    dcg = 0.0\n",
    "    for i, r in enumerate(recommended[:k], start=1):\n",
    "        if r in relevant:\n",
    "            dcg += 1.0 / math.log2(i + 1)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(recommended, relevant, k):\n",
    "    ideal = min(k, len(relevant))\n",
    "    if ideal == 0:\n",
    "        return 0.0\n",
    "    idcg = sum(1.0 / math.log2(i + 1) for i in range(1, ideal + 1))\n",
    "    return dcg_at_k(recommended, relevant, k) / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def mrr_at_k(recommended, relevant, k):\n",
    "    for i, r in enumerate(recommended[:k], start=1):\n",
    "        if r in relevant:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "def ap_at_k(recommended, relevant, k):\n",
    "    \"\"\"Average Precision@k.\"\"\"\n",
    "    if not relevant: return 0.0\n",
    "    ap, hits = 0.0, 0\n",
    "    for i, r in enumerate(recommended[:k], start=1):\n",
    "        if r in relevant:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / min(k, len(relevant)) if relevant else 0.0\n",
    "\n",
    "def hitrate_at_k(recommended, relevant, k):\n",
    "    \"\"\"1 if any relevant in top-k, else 0.\"\"\"\n",
    "    return 1.0 if any(r in relevant for r in recommended[:k]) else 0.0\n",
    "\n",
    "                                            \n",
    "UNSUPPORTED = {\"AUC\",\"ROC-AUC\",\"RMSE\",\"MAE\"}\n",
    "\n",
    "def compute_metric_for_system(name, topk_fn, K):\n",
    "    vals = []\n",
    "    for u in USERS:\n",
    "        rel = test_truth.get(u, set())\n",
    "        rec = topk_fn(u, K)\n",
    "        if name.startswith(\"Precision@\"):\n",
    "            vals.append(precision_at_k(rec, rel, K))\n",
    "        elif name.startswith(\"Recall@\"):\n",
    "            vals.append(recall_at_k(rec, rel, K))\n",
    "        elif name.startswith(\"nDCG@\"):\n",
    "            vals.append(ndcg_at_k(rec, rel, K))\n",
    "        elif name.startswith(\"MRR@\"):\n",
    "            vals.append(mrr_at_k(rec, rel, K))\n",
    "        elif name.startswith(\"MAP@\"):\n",
    "            vals.append(ap_at_k(rec, rel, K))\n",
    "        elif name.startswith(\"HitRate@\") or name.startswith(\"HR@\"):\n",
    "            vals.append(hitrate_at_k(rec, rel, K))\n",
    "        else:\n",
    "                                                      \n",
    "            return None\n",
    "    return float(np.mean(vals)) if vals else None\n",
    "\n",
    "                                                                               \n",
    "def parse_k(name):\n",
    "    m = re.search(r\"@(\\d+)\", name)\n",
    "    return int(m.group(1)) if m else 5\n",
    "\n",
    "rows = []\n",
    "skipped = []\n",
    "for mname in metric_names:\n",
    "    if any(tag in mname.upper() for tag in [\"AUC\",\"RMSE\",\"MAE\"]):\n",
    "        skipped.append(mname)\n",
    "        continue\n",
    "    K = parse_k(mname)\n",
    "    rows.append({\n",
    "        \"Metric\": mname,\n",
    "        \"Hybrid\": compute_metric_for_system(mname, topk_hybrid, K),\n",
    "    })\n",
    "\n",
    "metrics_table = pd.DataFrame(rows).set_index(\"Metric\").sort_index()\n",
    "display(metrics_table)\n",
    "\n",
    "if skipped:\n",
    "    print(\"[info] Skipped metrics that require explicit labels/scores:\", skipped)\n",
    "\n",
    "                \n",
    "metrics_table.to_csv(\"hybrid_metrics_using_WSM_Baseline_metric_names.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15ec8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>health_goal</th>\n",
       "      <th>physio name</th>\n",
       "      <th>specialities</th>\n",
       "      <th>athlete_rating</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>total_likes</th>\n",
       "      <th>videos_count</th>\n",
       "      <th>workout_recommendations</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Flexibility &amp; Mobility</td>\n",
       "      <td>Trainer 593</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>4.7</td>\n",
       "      <td>19</td>\n",
       "      <td>199143</td>\n",
       "      <td>317</td>\n",
       "      <td>191</td>\n",
       "      <td>0.301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Flexibility &amp; Mobility</td>\n",
       "      <td>Trainer 838</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>4.7</td>\n",
       "      <td>22</td>\n",
       "      <td>78568</td>\n",
       "      <td>453</td>\n",
       "      <td>192</td>\n",
       "      <td>0.285</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Flexibility &amp; Mobility</td>\n",
       "      <td>Trainer 657</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11</td>\n",
       "      <td>11264</td>\n",
       "      <td>28</td>\n",
       "      <td>67</td>\n",
       "      <td>0.264</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Flexibility &amp; Mobility</td>\n",
       "      <td>Trainer 339</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>247027</td>\n",
       "      <td>457</td>\n",
       "      <td>64</td>\n",
       "      <td>0.247</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Flexibility &amp; Mobility</td>\n",
       "      <td>Trainer 92</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15</td>\n",
       "      <td>295069</td>\n",
       "      <td>420</td>\n",
       "      <td>97</td>\n",
       "      <td>0.238</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id             health_goal  physio name specialities  athlete_rating  \\\n",
       "0        1  Flexibility & Mobility  Trainer 593  Flexibility             4.7   \n",
       "1        1  Flexibility & Mobility  Trainer 838  Flexibility             4.7   \n",
       "2        1  Flexibility & Mobility  Trainer 657  Flexibility             4.8   \n",
       "3        1  Flexibility & Mobility  Trainer 339  Flexibility             4.0   \n",
       "4        1  Flexibility & Mobility   Trainer 92  Flexibility             4.0   \n",
       "\n",
       "   years_experience  total_likes  videos_count  workout_recommendations  \\\n",
       "0                19       199143           317                      191   \n",
       "1                22        78568           453                      192   \n",
       "2                11        11264            28                       67   \n",
       "3                22       247027           457                       64   \n",
       "4                15       295069           420                       97   \n",
       "\n",
       "   score  rank  \n",
       "0  0.301     1  \n",
       "1  0.285     2  \n",
       "2  0.264     3  \n",
       "3  0.247     4  \n",
       "4  0.238     5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "100f071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>physio name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>physio_id</th>\n",
       "      <th>score</th>\n",
       "      <th>content_score</th>\n",
       "      <th>match_score</th>\n",
       "      <th>wsm_score</th>\n",
       "      <th>cf_score</th>\n",
       "      <th>is_cold_for_user</th>\n",
       "      <th>years_experience_tb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Trainer 593</td>\n",
       "      <td>1</td>\n",
       "      <td>593</td>\n",
       "      <td>0.301267</td>\n",
       "      <td>0.834737</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Trainer 838</td>\n",
       "      <td>1</td>\n",
       "      <td>838</td>\n",
       "      <td>0.284888</td>\n",
       "      <td>0.810129</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.816882</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Trainer 106</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0.280821</td>\n",
       "      <td>0.629806</td>\n",
       "      <td>0.286634</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.092906</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Trainer 771</td>\n",
       "      <td>1</td>\n",
       "      <td>771</td>\n",
       "      <td>0.278208</td>\n",
       "      <td>0.762426</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.737377</td>\n",
       "      <td>0.017475</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Trainer 298</td>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>0.274149</td>\n",
       "      <td>0.737496</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695827</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Trainer 256</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0.271840</td>\n",
       "      <td>0.757366</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.728944</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Trainer 657</td>\n",
       "      <td>1</td>\n",
       "      <td>657</td>\n",
       "      <td>0.263919</td>\n",
       "      <td>0.711624</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trainer 105</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0.263130</td>\n",
       "      <td>0.643538</td>\n",
       "      <td>0.298187</td>\n",
       "      <td>0.873771</td>\n",
       "      <td>0.058295</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Trainer 873</td>\n",
       "      <td>1</td>\n",
       "      <td>873</td>\n",
       "      <td>0.259819</td>\n",
       "      <td>0.738551</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.697584</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Trainer 305</td>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "      <td>0.258701</td>\n",
       "      <td>0.682555</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.894391</td>\n",
       "      <td>0.030472</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     physio name  user_id  physio_id     score  content_score  match_score  \\\n",
       "76   Trainer 593        1        593  0.301267       0.834737     0.800000   \n",
       "104  Trainer 838        1        838  0.284888       0.810129     0.800000   \n",
       "13   Trainer 106        1        106  0.280821       0.629806     0.286634   \n",
       "96   Trainer 771        1        771  0.278208       0.762426     0.800000   \n",
       "32   Trainer 298        1        298  0.274149       0.737496     0.800000   \n",
       "26   Trainer 256        1        256  0.271840       0.757366     0.800000   \n",
       "85   Trainer 657        1        657  0.263919       0.711624     0.800000   \n",
       "12   Trainer 105        1        105  0.263130       0.643538     0.298187   \n",
       "109  Trainer 873        1        873  0.259819       0.738551     0.800000   \n",
       "34   Trainer 305        1        305  0.258701       0.682555     0.364800   \n",
       "\n",
       "     wsm_score  cf_score  is_cold_for_user  years_experience_tb  \n",
       "76    0.857895  0.014013             False                   19  \n",
       "104   0.816882  0.002066              True                   22  \n",
       "13    0.858586  0.092906              True                   21  \n",
       "96    0.737377  0.017475              True                   19  \n",
       "32    0.695827  0.024655              True                   14  \n",
       "26    0.728944  0.010404              True                   16  \n",
       "85    0.652707  0.022847             False                   11  \n",
       "12    0.873771  0.058295              True                   22  \n",
       "109   0.697584  0.002041              True                    5  \n",
       "34    0.894391  0.030472              True                   11  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                                                    \n",
    "uid = 1\n",
    "diag_cols = [\"user_id\",\"physio_id\",\"score\",\"content_score\",\"match_score\",\"wsm_score\",\"cf_score\",\"is_cold_for_user\",\"years_experience_tb\"]\n",
    "(\n",
    "    cand[cand[\"user_id\"]==uid]\n",
    "      .merge(pt[[\"physio_id\", physio_name_col]], on=\"physio_id\", how=\"left\")\n",
    "      .rename(columns={physio_name_col: \"physio name\"})\n",
    "      .loc[:, [\"physio name\"] + diag_cols]\n",
    "      .sort_values(\"score\", ascending=False)\n",
    "      .head(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba04d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users in test: 40000  | users in train: 40000\n"
     ]
    }
   ],
   "source": [
    "                                                                           \n",
    "n_test_users = test_eng[\"user_id\"].nunique()\n",
    "n_train_users = train_eng[\"user_id\"].nunique()\n",
    "print(\"users in test:\", n_test_users, \" | users in train:\", n_train_users)\n",
    "\n",
    "                                                                 \n",
    "assert (test_eng.groupby(\"user_id\").size() >= 1).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f9b4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test interactions that are FIRST-EVER with that physio for the user: 120,563 / 160,324 (75.20%)\n",
      "…and repeats of a physio seen in train: 39,761 (24.80%)\n"
     ]
    }
   ],
   "source": [
    "                                                                   \n",
    "train_pairs = set(map(tuple, train_eng[[\"user_id\",\"physio_id\"]].itertuples(index=False, name=None)))\n",
    "test_pairs  = list(test_eng[[\"user_id\",\"physio_id\"]].itertuples(index=False, name=None))\n",
    "\n",
    "is_new = np.array([pair not in train_pairs for pair in test_pairs])\n",
    "print(f\"Test interactions that are FIRST-EVER with that physio for the user: {is_new.sum():,} / {len(is_new):,} \"\n",
    "      f\"({is_new.mean():.2%})\")\n",
    "print(f\"…and repeats of a physio seen in train: {(~is_new).sum():,} ({(~is_new).mean():.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}